슬라이드 1 안녕하십니까, 저는 '얼굴 인식 데이터 파이프라인'에 관한 발표를 맡은 하이든입니다

슬라이드 2  본 발표는 선정 이유, 개발 환경, 학습 과정, 앞으로의 발전 계획, 그리고 프로젝트를 하면서 느낀 점 대해 순차적으로 다룰 것입니다

슬라이드 3 선정 이유로는 컴퓨터비전과 배울랑교 수업을 들으면서 얼굴 인식과 이미지 처리에 관심이 생겨서 공부를 했고, 그러던 도중 교수님의 제안을 계기로  AI 랩실 웹사이트와 얼굴 인식 출퇴근 시스템을 개발하게 되었습니다.

슬라이드 4 구동방식을 대해 설명드리겠습니다. 출입문에 부착된 카메라가 촬영한 얼굴 이미지는 DB서버에 저장된 데이터와 유사도를 비교해 랩실 인원의 신원을 식별합니다. 이 정보는 웹사이트 서버에 자동으로 저장되어 이름, 출근 날짜와 시각, 당시의 사진 등이 저장되어 출퇴근 기록을 관리합니다.

슬라이드 5 

개발환경은 주로 Python을 사용하였고, TensorFlow를 통해 딥러닝 모델을 구축하고 훈련하였습니다. 또한 OpenCV를 활용하여 컴퓨터 비전과 이미지 처리 작업을 수행하였으며, FaceNet을 얼굴 인식 모델로 채택하였습니다.

슬라이드 6

학습 과정에서는 먼저, 랩실 인원들의 사진에서 얼굴을 감지 및 추출하는 기능이 필요했기 때문에 CNN 기반 얼굴 추출 알고리즘인 MTCNN을 이용해 Face Detection을 진행하였습니다.

슬라이드 7

10명의 랩실 인원들의 이미지를 수집하여  개별 얼굴을 추출해 플롯을 만들었고, 이를 활용해 데이터셋을 구성하였습니다. 감지된 각 얼굴에 대한 출력 레이블로 이름이 있는 데이터셋을 구성하였습니다.

슬라이드 8

여러 모델 중 가장 성능이 높았던 FaceNet을 사용해 얼굴 임베딩 벡터로 변환하고, 선형 서포트 벡터 머신을 이용해 얼굴 분류 예측을 수행했습니다. 이후 예측된 이름과 확률, 사진을 출력했는데요, 보시다시피 모델의 분류 정확도는 97%에 달했으나, 

슬라이드 9

분류 정확도는 트레인과 테스트셋에 대하여 각각  90, 81% 정도로, 비교적 잘 작동하지만 모델의 일반화 능력을 반드시 신뢰할 수 있다고는 생각하지 않았습니다. 이는 데이터셋의 크기가 적기 때문이라고 결론 내렸습니다. 하지만 20명 남짓한 랩실 인원 모두의 이미지를 모델 학습에 충분할 만큼 수집하기에는 시간적으로 무리가 있고, 효율성이 좋지 않다고 판단했습니다. 

슬라이드 10

따라서 모델의 성능을 높이고 오버피팅을 극복하기 위해 적은 수의 원본 이미지를 여러 처리를 통해 변형하여 데이터셋의 개수를 늘리는 이미지 증강 기법을 적용했습니다.

슬라이드 11 

전처리 레이어를 활용하여 다양한 이미지 증강 기법을 학습하였습니다.

슬라이드 12

좀 더 나은 전처리와 이미지 증강을 위해 다양한 영상 처리 기법 또한 학습하였습니다.

슬라이드 13

이 코드는 인풋 이미지를 넣으면 자동으로 전처리부터 영상 처리, 얼굴 분류가 진행되는 데이터 파이프라인을 완성한 코드입니다. 조금 더 자세히 설명해보자면 

슬라이드 14

인풋 데이터를 넣으면, 전처리가 진행되고, 이미지 증강을 통해 사용자가 원하는 만큼 사진을 생성합니다. 생성된 데이터셋에 대하여 train과 test 데이터가 자동으로 분류되어 각 폴더에 저장됩니다. 마지막으로 얼굴 분류를 수행합니다. 이것들이 자동으로 연결되어 순차적으로 실행되는 데이터 파이프 라인을 완성했습니다. 

슬라이드 15 

이를 통해 적은 데이터로도 다양한 이미지를 생성하고,

슬라이드 16 

소수의 사진을 가진 새로운 인물을 추가해도 분류가 잘되는 것을 확인할 수 있었습니다. 또한 이전의 모델보다 더 나은 정확도를 기록하며, 얼굴 인식 및 분류의 성능을 향상시키는 데 성공하였습니다.

슬라이드 17

앞으로의 발전 계획입니다. 현재 얼굴 인식 및 분류 파이프 라인, 랩실 웹 사이트, 카메라와 라즈베리 파이를 확보 및 완성해놓은 상태입니다. 따라서 이들을 연결하는 작업을 여름방학 동안 계속할 예정입니다. 그래서 2학기가 시작하기 전에  계획했던 얼굴 인식 출퇴근 관리 시스템을 완성하고 실사용할 계획입니다.

슬라이드 18

프로젝트를 하면서 느낀 점입니다. 개발환경을 구축하는 데 있어서 라이브러리와 모델 등의 호환성 문제 때문에 계속해서 오류가 나고 수정하는 것이 어려웠던 기억이 납니다. 또 한국어 자료가 드물어서 항상 영어로 문서를 읽어야 했던 점이 어려웠습니다. 하지만 혼자 문서를 보고 공부하면서 스스로 보완하고 알아가는 과정 자체가 좋은 연습이 되었습니다. 또한 작업을 하는 과정에서 깃허브와 리눅스 명령어 등에 능숙해지는 계기가 되었습니다.

슬라이드 19

이상으로 발표를 마치겠습니다.

=============================================================

예상 질문 답변 

Q 왜 TensorFlow를 선택하셨나요 파이토치, 케라스 등 다른 프레임워크도 많이 있습니다.

A 저희는 TensorFlow를 선택한 이유는 Google이 개발하고 있어 풍부한 문서와 지원을 제공하기 때문입니다. 대규모 데이터 처리와 복잡한 모델링에 특화된 플로우 그래프 구조와 유저 프렌들리한 공식 문서가 TensorFlow가 프로젝트에 가장 적합하다고 생각하게 만들었습니다.

Q OpenCV를 선택한 이유는 무엇인가요

A OpenCV는 이미지 처리 라이브러리 중에서 가장 널리 사용되며, 그 성능과 효율성, 호환성이 뛰어나다고 판단했습니다. 저희 프로젝트에서는 얼굴 인식과 같은 복잡한 작업을 OpenCV를 통해 효율적으로 수행할 수 있었습니다.

Q 왜 FaceNet을 주로 사용하셨나요

A FaceNet은 FaceNet, VGG-Face, DeepFace, OpenFace 등 얼굴 인식 모델 중에서 정확도와 효율성이 뛰어나다고 평가받고 있으며, 교과서적인, 베이직, 101한 점이 있어서 선택하게 되었습니다. 

직접 실행해본 결과 DeepFace는 모델이 복잡하고 속도가 느렸고, OpenFace는 데이터셋에 따라 성능이 너무 다르게 나왔습니다. 70% 

Q MTCNN을 선택한 이유는 무엇인가요

A  HOG(Histogram of Oriented Gradients), SSD(Single Shot MultiBox Detector), Faster R-CNN(Region-based Convolutional Neural Network) 

MTCNN은 다단계 컨볼루션 신경망을 사용하여 실시간 얼굴 인식에 적합한 빠른 속도와 높은 정확도를 제공하기 때문에 선택하게 되었습니다. 

CNN은 Convolutional Neural Network의 약자로, 컨볼루션 신경망을 의미합니다. 이는 주로 이미지 인식 및 처리에 사용되는 심층 학습 모델입니다. 컨볼루션은 두 함수 사이의 수학적 연산으로, 한 함수를 뒤집고 반전한 다음 다른 함수와 곱한 결과를 적분하여 새로운 함수를 생성하는 과정입니다. 이미지 처리에서는 입력 이미지와 필터(커널) 간의 컨볼루션을 통해 다양한 이미지 처리 작업을 수행할 수 있습니다. 이를 통해 이미지의 특징을 추출하거나 필터링하는 등의 작업을 할 수 있습니다.

CNN의 주요 구성 요소

- 합성곱 계층(Convolutional Layer) 입력 이미지에 대해 필터(커널)를 적용하여 특성 맵(feature map)을 생성합니다. 이는 이미지의 지역적 정보를 추출하는 역할을 합니다.
- 풀링 계층(Pooling Layer) 풀링은 특성 맵의 크기를 줄이는 작업을 수행하여 연산 속도를 향상시키고, 과적합을 줄이는 효과를 가집니다. 주로 최대 풀링(Max Pooling)이 사용됩니다.
- 활성화 함수(Activation Function) 주로 ReLU(Rectified Linear Unit)가 사용되며, 비선형성을 추가하여 네트워크가 복잡한 패턴을 학습할 수 있게 합니다.
- 완전 연결 계층(Fully Connected Layer) CNN의 마지막 부분에 위치하며, 이전 계층에서 추출된 특성들을 바탕으로 입력 데이터를 분류하거나 예측하는 역할을 합니다.

벡터=임베딩이란 이미지의 특징을 말하는데, 이미지 데이터셋은 고밀도, 고차원의 벡터이기 때문에 그대로 작업이 힘들어서 작업의 효율성을 위해서 저차원의 임베딩 벡터로 전환하는 과정이 필요합니다.

모델 성능 지표  Accuracy (정확도) 전체 데이터에서 올바르게 분류된 비율입니다. Precision (정밀도) 모델이 긍정 클래스로 예측한 것 중 실제로 긍정 클래스인 비율입니다. Recall (재현율) 실제 긍정 클래스 중에서 모델이 올바르게 예측한 비율입니다. F1-Score 정밀도와 재현율의 조화 평균. ROC-AUC 분류의 임계값에 대해 모델의 성능을 평가할 수 있습니다. 데이터의 다양성 다양한 조건(조명, 각도, 배경 등)에서 얼굴 이미지가 포함되어 있는지 확인합니다. 클래스 균형 각 클래스의 데이터가 균형 잡혀 있는지 확인합니다.

Q 선형 서포트 벡터 머신을 얼굴 분류에 사용한 이유는 무엇인가요

A 선형 서포트 벡터 머신은 이미지 처리와 같이 고차원 공간에서 선형 결정 경계를 학습하여 데이터를 효과적으로 분류할 수 있는 장점이 있습니다. 저희는 이 모델을 선택하여 데이터셋에 대한 얼굴 분류 예측을 수행하였고, 높은 정확도를 달성할 수 있었습니다.

SVM의 목표는 클래스 간의 분리 마진을 최대화하는 것입니다. 마진을 최대화함으로써 SVM은 일반화 성능을 높일 수 있습니다. 선형 SVM은 상대적으로 간단한 모델로, 복잡한 비선형 모델보다 과적합의 위험이 적습니다. 선형 SVM 동작 원리가 쉽습니다. 즉, 선형 결정 경계로도 충분히 높은 정확도를 달성할 수 있고 더 간단하고 해석이 용이하기 때문에, 선형으로 충분히 잘 작동한다면 굳이 복잡한 비선형 모델을 사용할 필요가 없습니다.

너무 한 게 없는데

여러 모델들을 사용해서 파라미터 조절해가면서 최적의 모델을 찾고자 했습니다. 그런 과정에서 예상보다 시간이 오래 걸렸습니다. 또한 목표가 완성보다는 공부였기 때문에 도서, 문서 등을 검색해가며 원리를 이해하면서 작업했기 때문에 그런 것 같습니다.